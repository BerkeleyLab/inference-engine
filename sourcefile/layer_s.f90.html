<!-- -*- mode: jinja2 -*- -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="Functional inference and training of surrogate models for computational science.">
    <meta name="author" content="Berkeley Lab" >
    <link rel="icon" href="../favicon.png">

    <title>layer_s.f90 &ndash; Fiats</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link href="../css/pygments.css" rel="stylesheet">
    <link href="../css/font-awesome.min.css" rel="stylesheet">
    <link href="../css/local.css" rel="stylesheet">
      <link  href="../tipuesearch/tipuesearch.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
    <script src="../js/svg-pan-zoom.min.js"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../index.html">Fiats </a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                  <li class="nav-item">
                    <a class="nav-link" href="../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/types.html">Derived Types</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/programs.html">Programs</a>
                </li>
            </ul>
              <div class="d-flex align-items-end flex-grow-1">
                <form action="../search.html" role="search" class="ms-auto">
                  <input type="text" class="form-control" aria-label="Search" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
                </form>
              </div>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>layer_s.f90
      <small>Source File</small>
      
    </h1>
      <div class="container p-2 mb-4 bg-light border rounded-3">
    <div class="row align-items-center justify-content-between" id="info-bar">
      <div class="col">
        <ul class="list-inline" style="margin-bottom:0px;display:inline">

            <li class="list-inline-item" id="statements"><i class="fa fa-list-ol"></i>
              <a data-bs-toggle="tooltip" data-bs-placement="bottom" data-bs-html="true"
                 title=" 6.2% of total for source files.">253 statements</a>
            </li>

            <li class="list-inline-item" id="source-file">
              <i class="fa fa-code"></i>
              <a href="../src/layer_s.f90"> Source File</a>
            </li>
        </ul>
      </div>
      <div class="col">
        <nav aria-label="breadcrumb">
          <ol class="breadcrumb justify-content-end mb-0">
            <li class="breadcrumb-item active" aria-current="page">layer_s.f90</li>
          </ol>
        </nav>
      </div>
    </div>
  </div>
  <script>
    $(function () {
    $('[data-bs-toggle="tooltip"]').tooltip()
    })
  </script>

  </div>
  <div class="row">
    <div class="col-md-3 hidden-xs hidden-sm visible-md visible-lg">
        <div id="sidebar">
      <h3>Contents</h3>
  
  
  
  
  
  
      <div class="card mb-4">
      <a data-bs-toggle="collapse" href="#submods-0"
         aria-expanded="false" aria-controls="submods-0">
         <h4 class="card-header bg-primary text-white">Submodules</h4>
      </a>
      <div id="submods-0" class="collapse">
        <div class="list-group list-group-flush">
            <a class="list-group-item" href="../module/layer_s.html">layer_s</a>
        </div>
      </div>
    </div>

  
  
  
  
  
  
  
  
  
  
  
  
  
    <div class="card card-primary">
      <div class="card-header text-left"><h3 class="card-title">Source Code</h3></div>
      <div class="list-group">
        <a class="list-group-item" href="../sourcefile/layer_s.f90.html#src">layer_s.f90</a>
      </div>
    </div>


  </div>

    </div>
    <div class="col-md-9" id='text'>
      
      <br>
        <div class="card">
          <div class="card-header">
            <h3 class="card-title">This file depends on</h3>
          </div>
          <div class="card-body">
            <div class="depgraph"><?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 12.1.2 (20240928.0832)
 -->
<!-- Title: sourcefile~~layer_s.f90~~EfferentGraph Pages: 1 -->
<svg id="sourcefilelayer_sf90EfferentGraph" width="641pt" height="218pt"
 viewBox="0.00 0.00 641.00 218.22" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="sourcefile~~layer_s.f90~~EfferentGraph" class="graph" transform="scale(0.611268 0.611268) rotate(0) translate(4 352.99)">
<title>sourcefile~~layer_s.f90~~EfferentGraph</title>
<polygon fill="white" stroke="none" points="-4,4 -4,-352.99 1044.64,-352.99 1044.64,4 -4,4"/>
<!-- sourcefile~layer_s.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node1" class="node">
<title>sourcefile~layer_s.f90</title>
<polygon fill="none" stroke="black" points="1040.64,-225.99 971.37,-225.99 971.37,-201.72 1040.64,-201.72 1040.64,-225.99"/>
<text text-anchor="middle" x="1006" y="-210.26" font-family="Helvetica,sans-Serif" font-size="10.50">layer_s.f90</text>
</g>
<!-- sourcefile~layer_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node2" class="node">
<title>sourcefile~layer_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node2"><a xlink:href="../sourcefile/layer_m.f90.html" xlink:title="layer_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="935.37,-225.99 860.85,-225.99 860.85,-201.72 935.37,-201.72 935.37,-225.99"/>
<text text-anchor="middle" x="898.11" y="-210.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">layer_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~layer_s.f90&#45;&gt;sourcefile~layer_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge1" class="edge">
<title>sourcefile~layer_s.f90&#45;&gt;sourcefile~layer_m.f90</title>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M970.92,-213.86C963.27,-213.86 955.03,-213.86 946.94,-213.86"/>
<polygon fill="#ff0000" stroke="#ff0000" points="947.21,-210.36 937.21,-213.86 947.21,-217.36 947.21,-210.36"/>
</g>
<!-- sourcefile~double_precision_string_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node3" class="node">
<title>sourcefile~double_precision_string_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node3"><a xlink:href="../sourcefile/double_precision_string_m.f90.html" xlink:title="double_precision_string_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="463.56,-268.99 290.79,-268.99 290.79,-244.72 463.56,-244.72 463.56,-268.99"/>
<text text-anchor="middle" x="377.18" y="-253.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">double_precision_string_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~layer_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge2" class="edge">
<title>sourcefile~layer_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90</title>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M758.84,-296.86C680.8,-311.49 659.5,-300.77 580.2,-296.86"/>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M578.2,-296.86C528.35,-294.39 472.77,-282.52 432.88,-272.35"/>
<polygon fill="#ff0000" stroke="#ff0000" points="433.82,-268.98 423.26,-269.84 432.06,-275.75 433.82,-268.98"/>
</g>
<!-- sourcefile~kind_parameters_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node4" class="node">
<title>sourcefile~kind_parameters_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node4"><a xlink:href="../sourcefile/kind_parameters_m.f90.html" xlink:title="kind_parameters_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="137.52,-102.99 0,-102.99 0,-78.72 137.52,-78.72 137.52,-102.99"/>
<text text-anchor="middle" x="68.76" y="-87.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">kind_parameters_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~layer_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge3" class="edge">
<title>sourcefile~layer_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90</title>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M578.2,-296.86C489.41,-292.47 463.67,-321.2 378.18,-296.86"/>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M376.18,-296.86C338.78,-286.21 325.82,-294.72 290.79,-277.86 251.88,-259.12 253.51,-236.7 215.16,-216.86"/>
</g>
<!-- sourcefile~metadata_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node5" class="node">
<title>sourcefile~metadata_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node5"><a xlink:href="../sourcefile/metadata_m.f90.html" xlink:title="metadata_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="628.83,-268.99 529.56,-268.99 529.56,-244.72 628.83,-244.72 628.83,-268.99"/>
<text text-anchor="middle" x="579.2" y="-253.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">metadata_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~layer_m.f90&#45;&gt;sourcefile~metadata_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge4" class="edge">
<title>sourcefile~layer_m.f90&#45;&gt;sourcefile~metadata_m.f90</title>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M758.84,-296.86C734.58,-301.4 673.99,-285.71 630.08,-272.66"/>
<polygon fill="#ff0000" stroke="#ff0000" points="631.35,-269.38 620.76,-269.85 629.33,-276.08 631.35,-269.38"/>
</g>
<!-- sourcefile~neural_network_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node6" class="node">
<title>sourcefile~neural_network_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node6"><a xlink:href="../sourcefile/neural_network_m.f90.html" xlink:title="neural_network_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="824.85,-163.99 694.83,-163.99 694.83,-139.72 824.85,-139.72 824.85,-163.99"/>
<text text-anchor="middle" x="759.84" y="-148.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">neural_network_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~layer_m.f90&#45;&gt;sourcefile~neural_network_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge5" class="edge">
<title>sourcefile~layer_m.f90&#45;&gt;sourcefile~neural_network_m.f90</title>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M869.53,-201.31C849.12,-192.02 821.08,-179.26 798.59,-169.03"/>
<polygon fill="#ff0000" stroke="#ff0000" points="800.3,-165.97 789.75,-165.01 797.41,-172.34 800.3,-165.97"/>
</g>
<!-- sourcefile~neuron_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node7" class="node">
<title>sourcefile~neuron_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node7"><a xlink:href="../sourcefile/neuron_m.f90.html" xlink:title="neuron_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="621.71,-348.99 536.69,-348.99 536.69,-324.72 621.71,-324.72 621.71,-348.99"/>
<text text-anchor="middle" x="579.2" y="-333.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">neuron_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~layer_m.f90&#45;&gt;sourcefile~neuron_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge6" class="edge">
<title>sourcefile~layer_m.f90&#45;&gt;sourcefile~neuron_m.f90</title>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M758.84,-296.86C716.28,-304.84 668.41,-315.65 632.95,-324.03"/>
<polygon fill="#ff0000" stroke="#ff0000" points="632.29,-320.59 623.37,-326.3 633.91,-327.4 632.29,-320.59"/>
</g>
<!-- sourcefile~tensor_map_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node8" class="node">
<title>sourcefile~tensor_map_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node8"><a xlink:href="../sourcefile/tensor_map_m.f90.html" xlink:title="tensor_map_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="634.46,-184.99 523.94,-184.99 523.94,-160.72 634.46,-160.72 634.46,-184.99"/>
<text text-anchor="middle" x="579.2" y="-169.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">tensor_map_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~layer_m.f90&#45;&gt;sourcefile~tensor_map_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge7" class="edge">
<title>sourcefile~layer_m.f90&#45;&gt;sourcefile~tensor_map_m.f90</title>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M884.21,-226.28C861.52,-246.99 812.03,-287.26 760.84,-296.86"/>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M758.84,-296.86C696.13,-308.61 713.87,-226.14 658.83,-193.86 654.53,-191.33 649.93,-189.11 645.18,-187.15"/>
<polygon fill="#ff0000" stroke="#ff0000" points="646.64,-183.95 636.04,-183.78 644.21,-190.52 646.64,-183.95"/>
</g>
<!-- sourcefile~metadata_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge8" class="edge">
<title>sourcefile~metadata_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90</title>
<path fill="none" stroke="#00ff00" stroke-dasharray="5,2" d="M529.26,-256.86C512.91,-256.86 494.05,-256.86 475.34,-256.86"/>
<polygon fill="#00ff00" stroke="#00ff00" points="475.55,-253.36 465.55,-256.86 475.55,-260.36 475.55,-253.36"/>
</g>
<!-- sourcefile~neural_network_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge11" class="edge">
<title>sourcefile~neural_network_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90</title>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M752.99,-139.34C740.16,-113.49 706.79,-54.57 658.83,-29.86 547.7,27.42 503.04,-17.02 378.18,-10.86"/>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M376.18,-10.86C304.72,-6.96 285.43,2.69 215.16,-10.86"/>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M213.16,-10.86C166.79,-19.8 120.38,-50.66 93.41,-71.34"/>
<polygon fill="#00ffff" stroke="#00ffff" points="91.27,-68.57 85.57,-77.5 95.6,-74.07 91.27,-68.57"/>
</g>
<!-- sourcefile~neural_network_m.f90&#45;&gt;sourcefile~metadata_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge12" class="edge">
<title>sourcefile~neural_network_m.f90&#45;&gt;sourcefile~metadata_m.f90</title>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M747.49,-164.38C730.16,-182.76 695.24,-216.91 658.83,-235.86 652.97,-238.91 646.62,-241.54 640.17,-243.81"/>
<polygon fill="#00ffff" stroke="#00ffff" points="639.17,-240.46 630.71,-246.84 641.3,-247.13 639.17,-240.46"/>
</g>
<!-- sourcefile~neural_network_m.f90&#45;&gt;sourcefile~tensor_map_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge15" class="edge">
<title>sourcefile~neural_network_m.f90&#45;&gt;sourcefile~tensor_map_m.f90</title>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M694.35,-159.44C678.66,-161.28 661.87,-163.25 646.12,-165.11"/>
<polygon fill="#00ffff" stroke="#00ffff" points="645.9,-161.61 636.37,-166.25 646.71,-168.56 645.9,-161.61"/>
</g>
<!-- sourcefile~activation_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node9" class="node">
<title>sourcefile~activation_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node9"><a xlink:href="../sourcefile/activation_m.f90.html" xlink:title="activation_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="629.21,-142.99 529.19,-142.99 529.19,-118.72 629.21,-118.72 629.21,-142.99"/>
<text text-anchor="middle" x="579.2" y="-127.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">activation_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~neural_network_m.f90&#45;&gt;sourcefile~activation_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge9" class="edge">
<title>sourcefile~neural_network_m.f90&#45;&gt;sourcefile~activation_m.f90</title>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M694.35,-144.27C676.8,-142.21 657.87,-139.99 640.56,-137.95"/>
<polygon fill="#00ffff" stroke="#00ffff" points="641.3,-134.51 630.96,-136.82 640.48,-141.47 641.3,-134.51"/>
</g>
<!-- sourcefile~double_precision_file_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node10" class="node">
<title>sourcefile~double_precision_file_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node10"><a xlink:href="../sourcefile/double_precision_file_m.f90.html" xlink:title="double_precision_file_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="658.83,-226.99 499.56,-226.99 499.56,-202.72 658.83,-202.72 658.83,-226.99"/>
<text text-anchor="middle" x="579.2" y="-211.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">double_precision_file_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~neural_network_m.f90&#45;&gt;sourcefile~double_precision_file_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge10" class="edge">
<title>sourcefile~neural_network_m.f90&#45;&gt;sourcefile~double_precision_file_m.f90</title>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M731.64,-164.47C711.74,-173.4 683.96,-185.27 658.83,-193.86 653.45,-195.69 647.82,-197.47 642.16,-199.16"/>
<polygon fill="#00ffff" stroke="#00ffff" points="641.35,-195.75 632.72,-201.89 643.29,-202.48 641.35,-195.75"/>
</g>
<!-- sourcefile~mini_batch_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node11" class="node">
<title>sourcefile~mini_batch_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node11"><a xlink:href="../sourcefile/mini_batch_m.f90.html" xlink:title="mini_batch_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="632.21,-62.99 526.19,-62.99 526.19,-38.72 632.21,-38.72 632.21,-62.99"/>
<text text-anchor="middle" x="579.2" y="-47.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">mini_batch_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~neural_network_m.f90&#45;&gt;sourcefile~mini_batch_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge13" class="edge">
<title>sourcefile~neural_network_m.f90&#45;&gt;sourcefile~mini_batch_m.f90</title>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M745.25,-139.36C726.87,-123.03 692.49,-94.44 658.83,-76.86 652.07,-73.32 644.73,-70.14 637.34,-67.31"/>
<polygon fill="#00ffff" stroke="#00ffff" points="638.57,-64.03 627.97,-63.93 636.19,-70.61 638.57,-64.03"/>
</g>
<!-- sourcefile~tensor_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node12" class="node">
<title>sourcefile~tensor_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node12"><a xlink:href="../sourcefile/tensor_m.f90.html" xlink:title="tensor_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="254.79,-102.99 173.52,-102.99 173.52,-78.72 254.79,-78.72 254.79,-102.99"/>
<text text-anchor="middle" x="214.16" y="-87.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">tensor_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~neural_network_m.f90&#45;&gt;sourcefile~tensor_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge14" class="edge">
<title>sourcefile~neural_network_m.f90&#45;&gt;sourcefile~tensor_m.f90</title>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M735.78,-139.39C715.99,-129.38 686.4,-116.03 658.83,-109.86 519.75,-78.73 350.19,-82.65 266.68,-87.23"/>
<polygon fill="#00ffff" stroke="#00ffff" points="266.53,-83.73 256.75,-87.8 266.94,-90.72 266.53,-83.73"/>
</g>
<!-- sourcefile~neuron_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge16" class="edge">
<title>sourcefile~neuron_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90</title>
<path fill="none" stroke="#0000ff" stroke-dasharray="5,2" d="M536.28,-325.92C524.09,-321.97 510.98,-316.95 499.56,-310.86 481.68,-301.31 481.55,-292.19 463.56,-282.86 456.55,-279.22 448.94,-276 441.26,-273.18"/>
<polygon fill="#0000ff" stroke="#0000ff" points="442.42,-269.88 431.83,-269.94 440.15,-276.5 442.42,-269.88"/>
</g>
<!-- sourcefile~neuron_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge17" class="edge">
<title>sourcefile~neuron_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90</title>
<path fill="none" stroke="#0000ff" stroke-dasharray="5,2" d="M536.36,-330.5C495.57,-323.83 431.99,-312.18 378.18,-296.86"/>
</g>
<!-- sourcefile~tensor_map_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge18" class="edge">
<title>sourcefile~tensor_map_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90</title>
<path fill="none" stroke="#ff00ff" stroke-dasharray="5,2" d="M523.77,-183.26C515.35,-186.02 507,-189.5 499.56,-193.86 479.76,-205.46 483.15,-218.92 463.56,-230.86 457.66,-234.45 451.21,-237.59 444.6,-240.31"/>
<polygon fill="#ff00ff" stroke="#ff00ff" points="443.67,-236.92 435.55,-243.72 446.14,-243.47 443.67,-236.92"/>
</g>
<!-- sourcefile~tensor_map_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge19" class="edge">
<title>sourcefile~tensor_map_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90</title>
<path fill="none" stroke="#ff00ff" stroke-dasharray="5,2" d="M376.18,-216.86C304.82,-211.34 278.72,-249.73 215.16,-216.86"/>
<path fill="none" stroke="#ff00ff" stroke-dasharray="5,2" d="M213.16,-216.86C161.09,-189.93 112.53,-140.07 87.47,-111.82"/>
<polygon fill="#ff00ff" stroke="#ff00ff" points="90.39,-109.84 81.19,-104.6 85.12,-114.44 90.39,-109.84"/>
</g>
<!-- sourcefile~tensor_map_m.f90&#45;&gt;sourcefile~tensor_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge20" class="edge">
<title>sourcefile~tensor_map_m.f90&#45;&gt;sourcefile~tensor_m.f90</title>
<path fill="none" stroke="#ff00ff" stroke-dasharray="5,2" d="M528.33,-185.41C474.07,-198.81 393.02,-218 378.18,-216.86"/>
<path fill="none" stroke="#ff00ff" stroke-dasharray="5,2" d="M376.18,-216.86C310.14,-211.75 254.83,-147.16 229.69,-112.5"/>
<polygon fill="#ff00ff" stroke="#ff00ff" points="232.63,-110.6 224.01,-104.44 226.91,-114.63 232.63,-110.6"/>
</g>
<!-- sourcefile~double_precision_file_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge21" class="edge">
<title>sourcefile~double_precision_file_m.f90&#45;&gt;sourcefile~double_precision_string_m.f90</title>
<path fill="none" stroke="#7fff00" stroke-dasharray="5,2" d="M518.18,-227.46C496.53,-232 471.87,-237.18 449.35,-241.91"/>
<polygon fill="#7fff00" stroke="#7fff00" points="448.69,-238.47 439.63,-243.95 450.13,-245.32 448.69,-238.47"/>
</g>
<!-- sourcefile~mini_batch_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge23" class="edge">
<title>sourcefile~mini_batch_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90</title>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M534.57,-38.25C494.36,-27.56 432.82,-13.55 378.18,-10.86"/>
</g>
<!-- sourcefile~input_output_pair_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_node13" class="node">
<title>sourcefile~input_output_pair_m.f90</title>
<g id="a_sourcefile~~layer_s.f90~~EfferentGraph_node13"><a xlink:href="../sourcefile/input_output_pair_m.f90.html" xlink:title="input_output_pair_m.f90">
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="447.44,-62.99 306.92,-62.99 306.92,-38.72 447.44,-38.72 447.44,-62.99"/>
<text text-anchor="middle" x="377.18" y="-47.26" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">input_output_pair_m.f90</text>
</a>
</g>
</g>
<!-- sourcefile~mini_batch_m.f90&#45;&gt;sourcefile~input_output_pair_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge22" class="edge">
<title>sourcefile~mini_batch_m.f90&#45;&gt;sourcefile~input_output_pair_m.f90</title>
<path fill="none" stroke="#00ffff" stroke-dasharray="5,2" d="M525.9,-50.86C505.51,-50.86 481.65,-50.86 459.13,-50.86"/>
<polygon fill="#00ffff" stroke="#00ffff" points="459.37,-47.36 449.37,-50.86 459.37,-54.36 459.37,-47.36"/>
</g>
<!-- sourcefile~tensor_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge24" class="edge">
<title>sourcefile~tensor_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90</title>
<path fill="none" stroke="#7f00ff" stroke-dasharray="5,2" d="M173.21,-90.86C165.63,-90.86 157.46,-90.86 149.15,-90.86"/>
<polygon fill="#7f00ff" stroke="#7f00ff" points="149.29,-87.36 139.29,-90.86 149.29,-94.36 149.29,-87.36"/>
</g>
<!-- sourcefile~input_output_pair_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge25" class="edge">
<title>sourcefile~input_output_pair_m.f90&#45;&gt;sourcefile~kind_parameters_m.f90</title>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M333.63,-38.32C289.96,-25.77 226.79,-8.61 215.16,-10.86"/>
</g>
<!-- sourcefile~input_output_pair_m.f90&#45;&gt;sourcefile~tensor_m.f90 -->
<g id="sourcefile~~layer_s.f90~~EfferentGraph_edge26" class="edge">
<title>sourcefile~input_output_pair_m.f90&#45;&gt;sourcefile~tensor_m.f90</title>
<path fill="none" stroke="#ff0000" stroke-dasharray="5,2" d="M325.67,-63.4C306.79,-68.09 285.35,-73.42 266.4,-78.13"/>
<polygon fill="#ff0000" stroke="#ff0000" points="265.61,-74.72 256.75,-80.52 267.29,-81.51 265.61,-74.72"/>
</g>
</g>
</svg>
</div>                <script>
                  var pansourcefilelayer_sf90EfferentGraph = svgPanZoom('#sourcefilelayer_sf90EfferentGraph',
                    {zoomEnabled: true, controlIconsEnabled: true, fit: true, center: true,}
                  );
                </script>          <div>
            <a type="button" class="graph-help" data-bs-toggle="modal" href="#EfferentGraph-help-text">Help</a>
          </div>
          <div class="modal fade" id="EfferentGraph-help-text" tabindex="-1" role="dialog">
            <div class="modal-dialog modal-lg" role="document">
              <div class="modal-content">
                <div class="modal-header">
                  <h4 class="modal-title" id="-graph-help-label">Graph Key</h4>
                  <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
<p>Nodes of different colours represent the following: </p>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 12.1.2 (20240928.0832)
 -->
<!-- Title: Graph Key Pages: 1 -->
<svg width="200pt" height="32pt"
 viewBox="0.00 0.00 199.52 32.27" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 28.27)">
<title>Graph Key</title>
<polygon fill="white" stroke="none" points="-4,4 -4,-28.27 195.52,-28.27 195.52,4 -4,4"/>
<!-- Source File -->
<g id="node1" class="node">
<title>Source File</title>
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="69.27,-24.27 0,-24.27 0,0 69.27,0 69.27,-24.27"/>
<text text-anchor="middle" x="34.63" y="-8.53" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Source File</text>
</g>
<!-- This Page&#39;s Entity -->
<g id="node2" class="node">
<title>This Page&#39;s Entity</title>
<polygon fill="none" stroke="black" points="191.52,-24.27 87.75,-24.27 87.75,0 191.52,0 191.52,-24.27"/>
<text text-anchor="middle" x="139.63" y="-8.53" font-family="Helvetica,sans-Serif" font-size="10.50">This Page&#39;s Entity</text>
</g>
</g>
</svg>

<p>Solid arrows point from a file to a file which it depends on. A file
is dependent upon another if the latter must be compiled before the former
can be.
</p>
 Where possible, edges connecting nodes are
given different colours to make them easier to distinguish in
large graphs.</div>
            </div>
          </div>
        </div>
          </div>
        </div>
<br>
      <section>
        <h2><span class="anchor" id="src"></span>Source Code</h2>
        <div class="hl codehilite"><pre><span></span><a id="ln-1" name="ln-1" href="#ln-1"></a><span class="c">! Copyright (c), The Regents of the University of California</span>
<a id="ln-2" name="ln-2" href="#ln-2"></a><span class="c">! Terms of use are as specified in LICENSE.txt</span>
<a id="ln-3" name="ln-3" href="#ln-3"></a><span class="k">submodule</span><span class="p">(</span><span class="n">layer_m</span><span class="p">)</span><span class="w"> </span><span class="n">layer_s</span>
<a id="ln-4" name="ln-4" href="#ln-4"></a><span class="w">  </span><span class="k">use </span><span class="n">assert_m</span><span class="p">,</span><span class="w"> </span><span class="k">only</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">assert</span>
<a id="ln-5" name="ln-5" href="#ln-5"></a><span class="w">  </span><span class="k">implicit none</span>
<a id="ln-6" name="ln-6" href="#ln-6"></a>
<a id="ln-7" name="ln-7" href="#ln-7"></a><span class="k">contains</span>
<a id="ln-8" name="ln-8" href="#ln-8"></a>
<a id="ln-9" name="ln-9" href="#ln-9"></a><span class="k">  module procedure </span><span class="n">default_real_construct_layer</span>
<a id="ln-10" name="ln-10" href="#ln-10"></a>
<a id="ln-11" name="ln-11" href="#ln-11"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">neuron_t</span><span class="p">),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w">  </span><span class="n">neuron</span><span class="w"> </span>
<a id="ln-12" name="ln-12" href="#ln-12"></a><span class="w">    </span><span class="kt">integer </span><span class="n">num_inputs</span><span class="p">,</span><span class="w"> </span><span class="n">neurons_in_layer</span>
<a id="ln-13" name="ln-13" href="#ln-13"></a><span class="w">    </span><span class="kt">character</span><span class="p">(</span><span class="nb">len</span><span class="o">=</span><span class="p">:),</span><span class="w"> </span><span class="k">allocatable</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">line</span>
<a id="ln-14" name="ln-14" href="#ln-14"></a><span class="w">    </span><span class="kt">logical </span><span class="n">hidden_layers</span><span class="p">,</span><span class="w"> </span><span class="n">output_layer</span>
<a id="ln-15" name="ln-15" href="#ln-15"></a>
<a id="ln-16" name="ln-16" href="#ln-16"></a><span class="w">    </span><span class="n">line</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">adjustl</span><span class="p">(</span><span class="n">layer_lines</span><span class="p">(</span><span class="n">start</span><span class="p">)%</span><span class="n">string</span><span class="p">())</span>
<a id="ln-17" name="ln-17" href="#ln-17"></a><span class="w">    </span><span class="n">hidden_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;[&#39;</span>
<a id="ln-18" name="ln-18" href="#ln-18"></a><span class="w">    </span><span class="n">output_layer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;&quot;output_layer&quot;: [&#39;</span>
<a id="ln-19" name="ln-19" href="#ln-19"></a><span class="w">    </span><span class="k">call </span><span class="n">assert</span><span class="p">(</span><span class="n">hidden_layers</span><span class="w"> </span><span class="p">.</span><span class="nb">or</span><span class="p">.</span><span class="w"> </span><span class="n">output_layer</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;layer_s(default_real_construct_layer): layer start&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">line</span><span class="p">)</span>
<a id="ln-20" name="ln-20" href="#ln-20"></a>
<a id="ln-21" name="ln-21" href="#ln-21"></a><span class="w">    </span><span class="n">layer</span><span class="p">%</span><span class="n">neuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neuron_t</span><span class="p">(</span><span class="n">layer_lines</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<a id="ln-22" name="ln-22" href="#ln-22"></a><span class="w">    </span><span class="n">num_inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">(</span><span class="n">layer</span><span class="p">%</span><span class="n">neuron</span><span class="p">%</span><span class="n">weights</span><span class="p">())</span>
<a id="ln-23" name="ln-23" href="#ln-23"></a>
<a id="ln-24" name="ln-24" href="#ln-24"></a><span class="w">    </span><span class="n">neuron</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-25" name="ln-25" href="#ln-25"></a><span class="w">    </span><span class="n">neurons_in_layer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-26" name="ln-26" href="#ln-26"></a><span class="w">    </span><span class="k">do </span>
<a id="ln-27" name="ln-27" href="#ln-27"></a><span class="k">      if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-28" name="ln-28" href="#ln-28"></a><span class="k">      </span><span class="n">neuron</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-29" name="ln-29" href="#ln-29"></a><span class="w">      </span><span class="k">call </span><span class="n">assert</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">neuron</span><span class="p">%</span><span class="n">weights</span><span class="p">())</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">num_inputs</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;layer_s(default_real_construct_layer): constant number of inputs&quot;</span><span class="p">)</span>
<a id="ln-30" name="ln-30" href="#ln-30"></a><span class="w">      </span><span class="n">neurons_in_layer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neurons_in_layer</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-31" name="ln-31" href="#ln-31"></a><span class="w">    </span><span class="k">end do</span>
<a id="ln-32" name="ln-32" href="#ln-32"></a>
<a id="ln-33" name="ln-33" href="#ln-33"></a><span class="k">    </span><span class="n">line</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">trim</span><span class="p">(</span><span class="nb">adjustl</span><span class="p">(</span><span class="n">layer_lines</span><span class="p">(</span><span class="n">start</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">neurons_in_layer</span><span class="o">+</span><span class="mi">1</span><span class="p">)%</span><span class="n">string</span><span class="p">()))</span>
<a id="ln-34" name="ln-34" href="#ln-34"></a><span class="w">    </span><span class="k">call </span><span class="n">assert</span><span class="p">(</span><span class="n">line</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span><span class="o">==</span><span class="s1">&#39;]&#39;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;layer_s(default_real_construct_layer): hidden layer end&quot;</span><span class="p">)</span>
<a id="ln-35" name="ln-35" href="#ln-35"></a>
<a id="ln-36" name="ln-36" href="#ln-36"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">line</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">):</span><span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">))</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;,&quot;</span><span class="p">)</span><span class="w"> </span><span class="n">layer</span><span class="p">%</span><span class="n">next</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer_t</span><span class="p">(</span><span class="n">layer_lines</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">neurons_in_layer</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
<a id="ln-37" name="ln-37" href="#ln-37"></a>
<a id="ln-38" name="ln-38" href="#ln-38"></a><span class="w">  </span><span class="k">end procedure</span>
<a id="ln-39" name="ln-39" href="#ln-39"></a>
<a id="ln-40" name="ln-40" href="#ln-40"></a><span class="k">  module procedure </span><span class="n">double_precision_construct_layer</span>
<a id="ln-41" name="ln-41" href="#ln-41"></a>
<a id="ln-42" name="ln-42" href="#ln-42"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">neuron_t</span><span class="p">(</span><span class="n">double_precision</span><span class="p">)),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w">  </span><span class="n">neuron</span><span class="w"> </span>
<a id="ln-43" name="ln-43" href="#ln-43"></a><span class="w">    </span><span class="kt">integer </span><span class="n">num_inputs</span><span class="p">,</span><span class="w"> </span><span class="n">neurons_in_layer</span>
<a id="ln-44" name="ln-44" href="#ln-44"></a><span class="w">    </span><span class="kt">character</span><span class="p">(</span><span class="nb">len</span><span class="o">=</span><span class="p">:),</span><span class="w"> </span><span class="k">allocatable</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">line</span>
<a id="ln-45" name="ln-45" href="#ln-45"></a><span class="w">    </span><span class="kt">logical </span><span class="n">hidden_layers</span><span class="p">,</span><span class="w"> </span><span class="n">output_layer</span>
<a id="ln-46" name="ln-46" href="#ln-46"></a>
<a id="ln-47" name="ln-47" href="#ln-47"></a><span class="w">    </span><span class="n">line</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">adjustl</span><span class="p">(</span><span class="n">layer_lines</span><span class="p">(</span><span class="n">start</span><span class="p">)%</span><span class="n">string</span><span class="p">())</span>
<a id="ln-48" name="ln-48" href="#ln-48"></a><span class="w">    </span><span class="n">hidden_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;[&#39;</span>
<a id="ln-49" name="ln-49" href="#ln-49"></a><span class="w">    </span><span class="n">output_layer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">&#39;&quot;output_layer&quot;: [&#39;</span>
<a id="ln-50" name="ln-50" href="#ln-50"></a><span class="w">    </span><span class="k">call </span><span class="n">assert</span><span class="p">(</span><span class="n">hidden_layers</span><span class="w"> </span><span class="p">.</span><span class="nb">or</span><span class="p">.</span><span class="w"> </span><span class="n">output_layer</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;layer_s(double_precision_construct_layer): layer start&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">line</span><span class="p">)</span>
<a id="ln-51" name="ln-51" href="#ln-51"></a>
<a id="ln-52" name="ln-52" href="#ln-52"></a><span class="w">    </span><span class="n">layer</span><span class="p">%</span><span class="n">neuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neuron_t</span><span class="p">(</span><span class="n">layer_lines</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<a id="ln-53" name="ln-53" href="#ln-53"></a><span class="w">    </span><span class="n">num_inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">(</span><span class="n">layer</span><span class="p">%</span><span class="n">neuron</span><span class="p">%</span><span class="n">weights</span><span class="p">())</span>
<a id="ln-54" name="ln-54" href="#ln-54"></a>
<a id="ln-55" name="ln-55" href="#ln-55"></a><span class="w">    </span><span class="n">neuron</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-56" name="ln-56" href="#ln-56"></a><span class="w">    </span><span class="n">neurons_in_layer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-57" name="ln-57" href="#ln-57"></a><span class="w">    </span><span class="k">do </span>
<a id="ln-58" name="ln-58" href="#ln-58"></a><span class="k">      if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-59" name="ln-59" href="#ln-59"></a><span class="k">      </span><span class="n">neuron</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-60" name="ln-60" href="#ln-60"></a><span class="w">      </span><span class="k">call </span><span class="n">assert</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">neuron</span><span class="p">%</span><span class="n">weights</span><span class="p">())</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">num_inputs</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;layer_s(double_precision_construct_layer): constant number of inputs&quot;</span><span class="p">)</span>
<a id="ln-61" name="ln-61" href="#ln-61"></a><span class="w">      </span><span class="n">neurons_in_layer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neurons_in_layer</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-62" name="ln-62" href="#ln-62"></a><span class="w">    </span><span class="k">end do</span>
<a id="ln-63" name="ln-63" href="#ln-63"></a>
<a id="ln-64" name="ln-64" href="#ln-64"></a><span class="k">    </span><span class="n">line</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">trim</span><span class="p">(</span><span class="nb">adjustl</span><span class="p">(</span><span class="n">layer_lines</span><span class="p">(</span><span class="n">start</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">neurons_in_layer</span><span class="o">+</span><span class="mi">1</span><span class="p">)%</span><span class="n">string</span><span class="p">()))</span>
<a id="ln-65" name="ln-65" href="#ln-65"></a><span class="w">    </span><span class="k">call </span><span class="n">assert</span><span class="p">(</span><span class="n">line</span><span class="p">(</span><span class="mi">1</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span><span class="o">==</span><span class="s1">&#39;]&#39;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;layer_s(double_precision_construct_layer): hidden layer end&quot;</span><span class="p">)</span>
<a id="ln-66" name="ln-66" href="#ln-66"></a>
<a id="ln-67" name="ln-67" href="#ln-67"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">line</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">):</span><span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">))</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;,&quot;</span><span class="p">)</span><span class="w"> </span><span class="n">layer</span><span class="p">%</span><span class="n">next</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer_t</span><span class="p">(</span><span class="n">layer_lines</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">neurons_in_layer</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
<a id="ln-68" name="ln-68" href="#ln-68"></a>
<a id="ln-69" name="ln-69" href="#ln-69"></a><span class="w">  </span><span class="k">end procedure</span>
<a id="ln-70" name="ln-70" href="#ln-70"></a>
<a id="ln-71" name="ln-71" href="#ln-71"></a><span class="k">  module procedure </span><span class="n">default_real_neural_network</span>
<a id="ln-72" name="ln-72" href="#ln-72"></a>
<a id="ln-73" name="ln-73" href="#ln-73"></a><span class="w">    </span><span class="k">associate</span><span class="p">(</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-74" name="ln-74" href="#ln-74"></a><span class="w">      </span><span class="n">num_inputs</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">hidden_layers</span><span class="p">%</span><span class="n">count_inputs</span><span class="p">(),</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-75" name="ln-75" href="#ln-75"></a><span class="w">      </span><span class="n">num_outputs</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">output_layer</span><span class="p">%</span><span class="n">count_neurons</span><span class="p">(),</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-76" name="ln-76" href="#ln-76"></a><span class="w">      </span><span class="n">neurons_per_hidden_layer</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">hidden_layers</span><span class="p">%</span><span class="n">count_neurons</span><span class="p">(),</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-77" name="ln-77" href="#ln-77"></a><span class="w">      </span><span class="n">num_hidden_layers</span><span class="w"> </span><span class="o">=&gt;</span><span class="w">  </span><span class="n">hidden_layers</span><span class="p">%</span><span class="n">count_layers</span><span class="p">(),</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-78" name="ln-78" href="#ln-78"></a><span class="w">      </span><span class="n">num_output_layers</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">output_layer</span><span class="p">%</span><span class="n">count_layers</span><span class="p">()</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-79" name="ln-79" href="#ln-79"></a><span class="w">    </span><span class="p">)</span><span class="w">   </span>
<a id="ln-80" name="ln-80" href="#ln-80"></a><span class="w">      </span><span class="k">call </span><span class="n">assert</span><span class="p">(</span><span class="n">num_output_layers</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;neural_network_s(default_real_neural_network): 1 output layer&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">num_output_layers</span><span class="p">)</span>
<a id="ln-81" name="ln-81" href="#ln-81"></a>
<a id="ln-82" name="ln-82" href="#ln-82"></a><span class="w">      </span><span class="k">associate</span><span class="p">(</span><span class="n">nodes</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">[</span><span class="n">num_inputs</span><span class="p">,</span><span class="w"> </span><span class="n">neurons_per_hidden_layer</span><span class="p">,</span><span class="w"> </span><span class="n">num_outputs</span><span class="p">])</span>
<a id="ln-83" name="ln-83" href="#ln-83"></a><span class="w">        </span><span class="k">associate</span><span class="p">(</span><span class="n">n_max</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="nb">maxval</span><span class="p">(</span><span class="n">nodes</span><span class="p">))</span>
<a id="ln-84" name="ln-84" href="#ln-84"></a><span class="w">          </span><span class="k">block</span>
<a id="ln-85" name="ln-85" href="#ln-85"></a><span class="k">            </span><span class="kt">real</span><span class="p">,</span><span class="w"> </span><span class="k">allocatable</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">weights</span><span class="p">(:,:,:),</span><span class="w"> </span><span class="n">biases</span><span class="p">(:,:)</span>
<a id="ln-86" name="ln-86" href="#ln-86"></a><span class="w">            </span><span class="k">type</span><span class="p">(</span><span class="n">layer_t</span><span class="p">),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">layer_ptr</span>
<a id="ln-87" name="ln-87" href="#ln-87"></a><span class="w">            </span><span class="k">type</span><span class="p">(</span><span class="n">neuron_t</span><span class="p">),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">neuron_ptr</span>
<a id="ln-88" name="ln-88" href="#ln-88"></a><span class="w">            </span><span class="kt">integer </span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="n">l</span>
<a id="ln-89" name="ln-89" href="#ln-89"></a>
<a id="ln-90" name="ln-90" href="#ln-90"></a><span class="w">            </span><span class="k">allocate</span><span class="p">(</span><span class="n">weights</span><span class="p">(</span><span class="n">n_max</span><span class="p">,</span><span class="w"> </span><span class="n">n_max</span><span class="p">,</span><span class="w"> </span><span class="n">num_hidden_layers</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">num_output_layers</span><span class="p">))</span>
<a id="ln-91" name="ln-91" href="#ln-91"></a><span class="w">            </span><span class="k">allocate</span><span class="p">(</span><span class="n">biases</span><span class="p">(</span><span class="n">n_max</span><span class="p">,</span><span class="w"> </span><span class="n">num_hidden_layers</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">num_output_layers</span><span class="p">))</span>
<a id="ln-92" name="ln-92" href="#ln-92"></a>
<a id="ln-93" name="ln-93" href="#ln-93"></a><span class="w">            </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">hidden_layers</span>
<a id="ln-94" name="ln-94" href="#ln-94"></a><span class="w">            </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span>
<a id="ln-95" name="ln-95" href="#ln-95"></a><span class="w">            </span><span class="n">loop_over_hidden_Layers</span><span class="p">:</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-96" name="ln-96" href="#ln-96"></a><span class="w">            </span><span class="k">do  </span>
<a id="ln-97" name="ln-97" href="#ln-97"></a><span class="k">              </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-98" name="ln-98" href="#ln-98"></a><span class="w">              </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-99" name="ln-99" href="#ln-99"></a><span class="w">              </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<a id="ln-100" name="ln-100" href="#ln-100"></a><span class="w">              </span><span class="n">loop_over_hidden_neurons</span><span class="p">:</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-101" name="ln-101" href="#ln-101"></a><span class="w">              </span><span class="k">do  </span>
<a id="ln-102" name="ln-102" href="#ln-102"></a><span class="k">                </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-103" name="ln-103" href="#ln-103"></a><span class="w">                </span><span class="k">associate</span><span class="p">(</span><span class="n">w</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">weights</span><span class="p">())</span>
<a id="ln-104" name="ln-104" href="#ln-104"></a><span class="w">                  </span><span class="n">weights</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">l</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">w</span>
<a id="ln-105" name="ln-105" href="#ln-105"></a><span class="w">                </span><span class="k">end associate</span>
<a id="ln-106" name="ln-106" href="#ln-106"></a><span class="k">                </span><span class="n">biases</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">l</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">bias</span><span class="p">()</span>
<a id="ln-107" name="ln-107" href="#ln-107"></a>
<a id="ln-108" name="ln-108" href="#ln-108"></a><span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-109" name="ln-109" href="#ln-109"></a><span class="k">                </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-110" name="ln-110" href="#ln-110"></a>
<a id="ln-111" name="ln-111" href="#ln-111"></a><span class="w">              </span><span class="k">end do </span><span class="n">loop_over_hidden_neurons</span>
<a id="ln-112" name="ln-112" href="#ln-112"></a>
<a id="ln-113" name="ln-113" href="#ln-113"></a><span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="nb">allocated</span><span class="p">(</span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span><span class="p">))</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-114" name="ln-114" href="#ln-114"></a><span class="k">              </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-115" name="ln-115" href="#ln-115"></a>
<a id="ln-116" name="ln-116" href="#ln-116"></a><span class="w">            </span><span class="k">end do </span><span class="n">loop_over_hidden_Layers</span>
<a id="ln-117" name="ln-117" href="#ln-117"></a>
<a id="ln-118" name="ln-118" href="#ln-118"></a><span class="w">            </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">output_layer</span>
<a id="ln-119" name="ln-119" href="#ln-119"></a><span class="w">            </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-120" name="ln-120" href="#ln-120"></a><span class="w">            </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-121" name="ln-121" href="#ln-121"></a><span class="w">            </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<a id="ln-122" name="ln-122" href="#ln-122"></a><span class="w">            </span><span class="n">loop_over_output_neurons</span><span class="p">:</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-123" name="ln-123" href="#ln-123"></a><span class="w">            </span><span class="k">do  </span>
<a id="ln-124" name="ln-124" href="#ln-124"></a><span class="k">              </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-125" name="ln-125" href="#ln-125"></a><span class="w">              </span><span class="k">associate</span><span class="p">(</span><span class="n">w</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">weights</span><span class="p">())</span>
<a id="ln-126" name="ln-126" href="#ln-126"></a><span class="w">                </span><span class="n">weights</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">l</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">w</span>
<a id="ln-127" name="ln-127" href="#ln-127"></a><span class="w">              </span><span class="k">end associate</span>
<a id="ln-128" name="ln-128" href="#ln-128"></a><span class="k">              </span><span class="n">biases</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">l</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">bias</span><span class="p">()</span>
<a id="ln-129" name="ln-129" href="#ln-129"></a>
<a id="ln-130" name="ln-130" href="#ln-130"></a><span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-131" name="ln-131" href="#ln-131"></a><span class="k">              </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-132" name="ln-132" href="#ln-132"></a>
<a id="ln-133" name="ln-133" href="#ln-133"></a><span class="w">            </span><span class="k">end do </span><span class="n">loop_over_output_neurons</span>
<a id="ln-134" name="ln-134" href="#ln-134"></a>
<a id="ln-135" name="ln-135" href="#ln-135"></a><span class="w">            </span><span class="n">neural_network_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neural_network_t</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="n">biases</span><span class="p">,</span><span class="w"> </span><span class="n">nodes</span><span class="p">,</span><span class="w"> </span><span class="n">input_map</span><span class="p">,</span><span class="w"> </span><span class="n">output_map</span><span class="p">)</span>
<a id="ln-136" name="ln-136" href="#ln-136"></a><span class="w">          </span><span class="k">end block</span>
<a id="ln-137" name="ln-137" href="#ln-137"></a><span class="k">        end associate</span>
<a id="ln-138" name="ln-138" href="#ln-138"></a><span class="k">      end associate</span>
<a id="ln-139" name="ln-139" href="#ln-139"></a><span class="k">    end associate</span>
<a id="ln-140" name="ln-140" href="#ln-140"></a><span class="k">    </span>
<a id="ln-141" name="ln-141" href="#ln-141"></a><span class="k">  end procedure </span><span class="n">default_real_neural_network</span>
<a id="ln-142" name="ln-142" href="#ln-142"></a>
<a id="ln-143" name="ln-143" href="#ln-143"></a><span class="w">  </span><span class="k">module procedure </span><span class="n">double_precision_neural_network</span>
<a id="ln-144" name="ln-144" href="#ln-144"></a>
<a id="ln-145" name="ln-145" href="#ln-145"></a><span class="w">    </span><span class="k">associate</span><span class="p">(</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-146" name="ln-146" href="#ln-146"></a><span class="w">      </span><span class="n">num_inputs</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">hidden_layers</span><span class="p">%</span><span class="n">count_inputs</span><span class="p">(),</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-147" name="ln-147" href="#ln-147"></a><span class="w">      </span><span class="n">num_outputs</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">output_layer</span><span class="p">%</span><span class="n">count_neurons</span><span class="p">(),</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-148" name="ln-148" href="#ln-148"></a><span class="w">      </span><span class="n">neurons_per_hidden_layer</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">hidden_layers</span><span class="p">%</span><span class="n">count_neurons</span><span class="p">(),</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-149" name="ln-149" href="#ln-149"></a><span class="w">      </span><span class="n">num_hidden_layers</span><span class="w"> </span><span class="o">=&gt;</span><span class="w">  </span><span class="n">hidden_layers</span><span class="p">%</span><span class="n">count_layers</span><span class="p">(),</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-150" name="ln-150" href="#ln-150"></a><span class="w">      </span><span class="n">num_output_layers</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">output_layer</span><span class="p">%</span><span class="n">count_layers</span><span class="p">()</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-151" name="ln-151" href="#ln-151"></a><span class="w">    </span><span class="p">)</span><span class="w">   </span>
<a id="ln-152" name="ln-152" href="#ln-152"></a><span class="w">      </span><span class="k">call </span><span class="n">assert</span><span class="p">(</span><span class="n">num_output_layers</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;neural_network_s(double_precision_neural_network): 1 output layer&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">num_output_layers</span><span class="p">)</span>
<a id="ln-153" name="ln-153" href="#ln-153"></a>
<a id="ln-154" name="ln-154" href="#ln-154"></a><span class="w">      </span><span class="k">associate</span><span class="p">(</span><span class="n">nodes</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">[</span><span class="n">num_inputs</span><span class="p">,</span><span class="w"> </span><span class="n">neurons_per_hidden_layer</span><span class="p">,</span><span class="w"> </span><span class="n">num_outputs</span><span class="p">])</span>
<a id="ln-155" name="ln-155" href="#ln-155"></a><span class="w">        </span><span class="k">associate</span><span class="p">(</span><span class="n">n_max</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="nb">maxval</span><span class="p">(</span><span class="n">nodes</span><span class="p">))</span>
<a id="ln-156" name="ln-156" href="#ln-156"></a><span class="w">          </span><span class="k">block</span>
<a id="ln-157" name="ln-157" href="#ln-157"></a><span class="k">            </span><span class="kt">double precision</span><span class="p">,</span><span class="w"> </span><span class="k">allocatable</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">weights</span><span class="p">(:,:,:),</span><span class="w"> </span><span class="n">biases</span><span class="p">(:,:)</span>
<a id="ln-158" name="ln-158" href="#ln-158"></a><span class="w">            </span><span class="k">type</span><span class="p">(</span><span class="n">layer_t</span><span class="p">(</span><span class="n">double_precision</span><span class="p">)),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">layer_ptr</span>
<a id="ln-159" name="ln-159" href="#ln-159"></a><span class="w">            </span><span class="k">type</span><span class="p">(</span><span class="n">neuron_t</span><span class="p">(</span><span class="n">double_precision</span><span class="p">)),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">neuron_ptr</span>
<a id="ln-160" name="ln-160" href="#ln-160"></a><span class="w">            </span><span class="kt">integer </span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="n">l</span>
<a id="ln-161" name="ln-161" href="#ln-161"></a>
<a id="ln-162" name="ln-162" href="#ln-162"></a><span class="w">            </span><span class="k">allocate</span><span class="p">(</span><span class="n">weights</span><span class="p">(</span><span class="n">n_max</span><span class="p">,</span><span class="w"> </span><span class="n">n_max</span><span class="p">,</span><span class="w"> </span><span class="n">num_hidden_layers</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">num_output_layers</span><span class="p">))</span>
<a id="ln-163" name="ln-163" href="#ln-163"></a><span class="w">            </span><span class="k">allocate</span><span class="p">(</span><span class="n">biases</span><span class="p">(</span><span class="n">n_max</span><span class="p">,</span><span class="w"> </span><span class="n">num_hidden_layers</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">num_output_layers</span><span class="p">))</span>
<a id="ln-164" name="ln-164" href="#ln-164"></a>
<a id="ln-165" name="ln-165" href="#ln-165"></a><span class="w">            </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">hidden_layers</span>
<a id="ln-166" name="ln-166" href="#ln-166"></a><span class="w">            </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span>
<a id="ln-167" name="ln-167" href="#ln-167"></a><span class="w">            </span><span class="n">loop_over_hidden_Layers</span><span class="p">:</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-168" name="ln-168" href="#ln-168"></a><span class="w">            </span><span class="k">do  </span>
<a id="ln-169" name="ln-169" href="#ln-169"></a><span class="k">              </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-170" name="ln-170" href="#ln-170"></a><span class="w">              </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-171" name="ln-171" href="#ln-171"></a><span class="w">              </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<a id="ln-172" name="ln-172" href="#ln-172"></a><span class="w">              </span><span class="n">loop_over_hidden_neurons</span><span class="p">:</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-173" name="ln-173" href="#ln-173"></a><span class="w">              </span><span class="k">do  </span>
<a id="ln-174" name="ln-174" href="#ln-174"></a><span class="k">                </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-175" name="ln-175" href="#ln-175"></a><span class="w">                </span><span class="k">associate</span><span class="p">(</span><span class="n">w</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">weights</span><span class="p">())</span>
<a id="ln-176" name="ln-176" href="#ln-176"></a><span class="w">                  </span><span class="n">weights</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">l</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">w</span>
<a id="ln-177" name="ln-177" href="#ln-177"></a><span class="w">                </span><span class="k">end associate</span>
<a id="ln-178" name="ln-178" href="#ln-178"></a><span class="k">                </span><span class="n">biases</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">l</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">bias</span><span class="p">()</span>
<a id="ln-179" name="ln-179" href="#ln-179"></a>
<a id="ln-180" name="ln-180" href="#ln-180"></a><span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-181" name="ln-181" href="#ln-181"></a><span class="k">                </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-182" name="ln-182" href="#ln-182"></a>
<a id="ln-183" name="ln-183" href="#ln-183"></a><span class="w">              </span><span class="k">end do </span><span class="n">loop_over_hidden_neurons</span>
<a id="ln-184" name="ln-184" href="#ln-184"></a>
<a id="ln-185" name="ln-185" href="#ln-185"></a><span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="nb">allocated</span><span class="p">(</span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span><span class="p">))</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-186" name="ln-186" href="#ln-186"></a><span class="k">              </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-187" name="ln-187" href="#ln-187"></a>
<a id="ln-188" name="ln-188" href="#ln-188"></a><span class="w">            </span><span class="k">end do </span><span class="n">loop_over_hidden_Layers</span>
<a id="ln-189" name="ln-189" href="#ln-189"></a>
<a id="ln-190" name="ln-190" href="#ln-190"></a><span class="w">            </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">output_layer</span>
<a id="ln-191" name="ln-191" href="#ln-191"></a><span class="w">            </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-192" name="ln-192" href="#ln-192"></a><span class="w">            </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-193" name="ln-193" href="#ln-193"></a><span class="w">            </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<a id="ln-194" name="ln-194" href="#ln-194"></a><span class="w">            </span><span class="n">loop_over_output_neurons</span><span class="p">:</span><span class="w"> </span><span class="p">&amp;</span>
<a id="ln-195" name="ln-195" href="#ln-195"></a><span class="w">            </span><span class="k">do  </span>
<a id="ln-196" name="ln-196" href="#ln-196"></a><span class="k">              </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-197" name="ln-197" href="#ln-197"></a><span class="w">              </span><span class="k">associate</span><span class="p">(</span><span class="n">w</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">weights</span><span class="p">())</span>
<a id="ln-198" name="ln-198" href="#ln-198"></a><span class="w">                </span><span class="n">weights</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">l</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">w</span>
<a id="ln-199" name="ln-199" href="#ln-199"></a><span class="w">              </span><span class="k">end associate</span>
<a id="ln-200" name="ln-200" href="#ln-200"></a><span class="k">              </span><span class="n">biases</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">l</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">bias</span><span class="p">()</span>
<a id="ln-201" name="ln-201" href="#ln-201"></a>
<a id="ln-202" name="ln-202" href="#ln-202"></a><span class="w">              </span><span class="k">if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-203" name="ln-203" href="#ln-203"></a><span class="k">              </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-204" name="ln-204" href="#ln-204"></a>
<a id="ln-205" name="ln-205" href="#ln-205"></a><span class="w">            </span><span class="k">end do </span><span class="n">loop_over_output_neurons</span>
<a id="ln-206" name="ln-206" href="#ln-206"></a>
<a id="ln-207" name="ln-207" href="#ln-207"></a><span class="w">            </span><span class="n">neural_network_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neural_network_t</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="n">biases</span><span class="p">,</span><span class="w"> </span><span class="n">nodes</span><span class="p">,</span><span class="w"> </span><span class="n">input_map</span><span class="p">,</span><span class="w"> </span><span class="n">output_map</span><span class="p">)</span>
<a id="ln-208" name="ln-208" href="#ln-208"></a><span class="w">          </span><span class="k">end block</span>
<a id="ln-209" name="ln-209" href="#ln-209"></a><span class="k">        end associate</span>
<a id="ln-210" name="ln-210" href="#ln-210"></a><span class="k">      end associate</span>
<a id="ln-211" name="ln-211" href="#ln-211"></a><span class="k">    end associate</span>
<a id="ln-212" name="ln-212" href="#ln-212"></a><span class="k">    </span>
<a id="ln-213" name="ln-213" href="#ln-213"></a><span class="k">  end procedure </span><span class="n">double_precision_neural_network</span>
<a id="ln-214" name="ln-214" href="#ln-214"></a>
<a id="ln-215" name="ln-215" href="#ln-215"></a><span class="w">  </span><span class="k">module procedure </span><span class="n">default_real_count_layers</span>
<a id="ln-216" name="ln-216" href="#ln-216"></a>
<a id="ln-217" name="ln-217" href="#ln-217"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">layer_t</span><span class="p">),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">layer_ptr</span>
<a id="ln-218" name="ln-218" href="#ln-218"></a>
<a id="ln-219" name="ln-219" href="#ln-219"></a><span class="w">    </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer</span>
<a id="ln-220" name="ln-220" href="#ln-220"></a><span class="w">    </span><span class="n">num_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span>
<a id="ln-221" name="ln-221" href="#ln-221"></a><span class="w">    </span><span class="k">do  </span>
<a id="ln-222" name="ln-222" href="#ln-222"></a><span class="k">      if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="nb">allocated</span><span class="p">(</span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span><span class="p">))</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-223" name="ln-223" href="#ln-223"></a><span class="k">      </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span>
<a id="ln-224" name="ln-224" href="#ln-224"></a><span class="w">      </span><span class="n">num_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_layers</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span>
<a id="ln-225" name="ln-225" href="#ln-225"></a><span class="w">    </span><span class="k">end do</span>
<a id="ln-226" name="ln-226" href="#ln-226"></a>
<a id="ln-227" name="ln-227" href="#ln-227"></a><span class="k">  end procedure</span>
<a id="ln-228" name="ln-228" href="#ln-228"></a>
<a id="ln-229" name="ln-229" href="#ln-229"></a><span class="k">  module procedure </span><span class="n">double_precision_count_layers</span>
<a id="ln-230" name="ln-230" href="#ln-230"></a>
<a id="ln-231" name="ln-231" href="#ln-231"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">layer_t</span><span class="p">(</span><span class="n">double_precision</span><span class="p">)),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">layer_ptr</span>
<a id="ln-232" name="ln-232" href="#ln-232"></a>
<a id="ln-233" name="ln-233" href="#ln-233"></a><span class="w">    </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer</span>
<a id="ln-234" name="ln-234" href="#ln-234"></a><span class="w">    </span><span class="n">num_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span>
<a id="ln-235" name="ln-235" href="#ln-235"></a><span class="w">    </span><span class="k">do  </span>
<a id="ln-236" name="ln-236" href="#ln-236"></a><span class="k">      if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="nb">allocated</span><span class="p">(</span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span><span class="p">))</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-237" name="ln-237" href="#ln-237"></a><span class="k">      </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span>
<a id="ln-238" name="ln-238" href="#ln-238"></a><span class="w">      </span><span class="n">num_layers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_layers</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span>
<a id="ln-239" name="ln-239" href="#ln-239"></a><span class="w">    </span><span class="k">end do</span>
<a id="ln-240" name="ln-240" href="#ln-240"></a>
<a id="ln-241" name="ln-241" href="#ln-241"></a><span class="k">  end procedure</span>
<a id="ln-242" name="ln-242" href="#ln-242"></a>
<a id="ln-243" name="ln-243" href="#ln-243"></a><span class="k">  module procedure </span><span class="n">default_real_count_neurons</span>
<a id="ln-244" name="ln-244" href="#ln-244"></a>
<a id="ln-245" name="ln-245" href="#ln-245"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">layer_t</span><span class="p">),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">layer_ptr</span>
<a id="ln-246" name="ln-246" href="#ln-246"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">neuron_t</span><span class="p">),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">neuron_ptr</span>
<a id="ln-247" name="ln-247" href="#ln-247"></a><span class="w">    </span><span class="kt">integer </span><span class="n">num_neurons</span>
<a id="ln-248" name="ln-248" href="#ln-248"></a>
<a id="ln-249" name="ln-249" href="#ln-249"></a><span class="w">    </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer</span>
<a id="ln-250" name="ln-250" href="#ln-250"></a>
<a id="ln-251" name="ln-251" href="#ln-251"></a><span class="w">    </span><span class="k">allocate</span><span class="p">(</span><span class="n">neurons_per_layer_result</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<a id="ln-252" name="ln-252" href="#ln-252"></a>
<a id="ln-253" name="ln-253" href="#ln-253"></a><span class="w">    </span><span class="k">do  </span>
<a id="ln-254" name="ln-254" href="#ln-254"></a><span class="k">      </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span>
<a id="ln-255" name="ln-255" href="#ln-255"></a><span class="w">      </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-256" name="ln-256" href="#ln-256"></a><span class="w">      </span><span class="k">do  </span>
<a id="ln-257" name="ln-257" href="#ln-257"></a><span class="k">        if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-258" name="ln-258" href="#ln-258"></a><span class="k">        </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-259" name="ln-259" href="#ln-259"></a><span class="w">        </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span>
<a id="ln-260" name="ln-260" href="#ln-260"></a><span class="w">      </span><span class="k">end do</span>
<a id="ln-261" name="ln-261" href="#ln-261"></a><span class="k">      </span><span class="n">neurons_per_layer_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">neurons_per_layer_result</span><span class="p">,</span><span class="w"> </span><span class="n">num_neurons</span><span class="p">]</span>
<a id="ln-262" name="ln-262" href="#ln-262"></a><span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="nb">allocated</span><span class="p">(</span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span><span class="p">))</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-263" name="ln-263" href="#ln-263"></a><span class="k">      </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span>
<a id="ln-264" name="ln-264" href="#ln-264"></a><span class="w">    </span><span class="k">end do</span>
<a id="ln-265" name="ln-265" href="#ln-265"></a><span class="k"> </span>
<a id="ln-266" name="ln-266" href="#ln-266"></a><span class="k">  end procedure</span>
<a id="ln-267" name="ln-267" href="#ln-267"></a>
<a id="ln-268" name="ln-268" href="#ln-268"></a><span class="k">  module procedure </span><span class="n">double_precision_count_neurons</span>
<a id="ln-269" name="ln-269" href="#ln-269"></a>
<a id="ln-270" name="ln-270" href="#ln-270"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">layer_t</span><span class="p">(</span><span class="n">double_precision</span><span class="p">)),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">layer_ptr</span>
<a id="ln-271" name="ln-271" href="#ln-271"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">neuron_t</span><span class="p">(</span><span class="n">double_precision</span><span class="p">)),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">neuron_ptr</span>
<a id="ln-272" name="ln-272" href="#ln-272"></a><span class="w">    </span><span class="kt">integer </span><span class="n">num_neurons</span>
<a id="ln-273" name="ln-273" href="#ln-273"></a>
<a id="ln-274" name="ln-274" href="#ln-274"></a><span class="w">    </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer</span>
<a id="ln-275" name="ln-275" href="#ln-275"></a>
<a id="ln-276" name="ln-276" href="#ln-276"></a><span class="w">    </span><span class="k">allocate</span><span class="p">(</span><span class="n">neurons_per_layer_result</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<a id="ln-277" name="ln-277" href="#ln-277"></a>
<a id="ln-278" name="ln-278" href="#ln-278"></a><span class="w">    </span><span class="k">do  </span>
<a id="ln-279" name="ln-279" href="#ln-279"></a><span class="k">      </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span>
<a id="ln-280" name="ln-280" href="#ln-280"></a><span class="w">      </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-281" name="ln-281" href="#ln-281"></a><span class="w">      </span><span class="k">do  </span>
<a id="ln-282" name="ln-282" href="#ln-282"></a><span class="k">        if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-283" name="ln-283" href="#ln-283"></a><span class="k">        </span><span class="n">neuron_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron_ptr</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-284" name="ln-284" href="#ln-284"></a><span class="w">        </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span>
<a id="ln-285" name="ln-285" href="#ln-285"></a><span class="w">      </span><span class="k">end do</span>
<a id="ln-286" name="ln-286" href="#ln-286"></a><span class="k">      </span><span class="n">neurons_per_layer_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">neurons_per_layer_result</span><span class="p">,</span><span class="w"> </span><span class="n">num_neurons</span><span class="p">]</span>
<a id="ln-287" name="ln-287" href="#ln-287"></a><span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="nb">allocated</span><span class="p">(</span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span><span class="p">))</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-288" name="ln-288" href="#ln-288"></a><span class="k">      </span><span class="n">layer_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">layer_ptr</span><span class="p">%</span><span class="n">next</span>
<a id="ln-289" name="ln-289" href="#ln-289"></a><span class="w">    </span><span class="k">end do</span>
<a id="ln-290" name="ln-290" href="#ln-290"></a><span class="k"> </span>
<a id="ln-291" name="ln-291" href="#ln-291"></a><span class="k">  end procedure</span>
<a id="ln-292" name="ln-292" href="#ln-292"></a>
<a id="ln-293" name="ln-293" href="#ln-293"></a><span class="k">  module procedure </span><span class="n">default_real_count_inputs</span>
<a id="ln-294" name="ln-294" href="#ln-294"></a><span class="w">    </span><span class="n">num_inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer</span><span class="p">%</span><span class="n">neuron</span><span class="p">%</span><span class="n">num_inputs</span><span class="p">()</span><span class="w"> </span><span class="c">! assume fully connected input layer</span>
<a id="ln-295" name="ln-295" href="#ln-295"></a><span class="w">  </span><span class="k">end procedure</span>
<a id="ln-296" name="ln-296" href="#ln-296"></a>
<a id="ln-297" name="ln-297" href="#ln-297"></a><span class="k">  module procedure </span><span class="n">double_precision_count_inputs</span>
<a id="ln-298" name="ln-298" href="#ln-298"></a><span class="w">    </span><span class="n">num_inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer</span><span class="p">%</span><span class="n">neuron</span><span class="p">%</span><span class="n">num_inputs</span><span class="p">()</span><span class="w"> </span><span class="c">! assume fully connected input layer</span>
<a id="ln-299" name="ln-299" href="#ln-299"></a><span class="w">  </span><span class="k">end procedure</span>
<a id="ln-300" name="ln-300" href="#ln-300"></a>
<a id="ln-301" name="ln-301" href="#ln-301"></a><span class="k">  module procedure </span><span class="n">default_real_neurons_per_layer</span>
<a id="ln-302" name="ln-302" href="#ln-302"></a>
<a id="ln-303" name="ln-303" href="#ln-303"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">neuron_t</span><span class="p">),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w">  </span><span class="n">neuron</span><span class="w"> </span>
<a id="ln-304" name="ln-304" href="#ln-304"></a>
<a id="ln-305" name="ln-305" href="#ln-305"></a><span class="w">    </span><span class="n">neuron</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">self</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-306" name="ln-306" href="#ln-306"></a><span class="w">    </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-307" name="ln-307" href="#ln-307"></a><span class="w">    </span><span class="k">do </span>
<a id="ln-308" name="ln-308" href="#ln-308"></a><span class="k">      if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-309" name="ln-309" href="#ln-309"></a><span class="k">      </span><span class="n">neuron</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-310" name="ln-310" href="#ln-310"></a><span class="w">      </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-311" name="ln-311" href="#ln-311"></a><span class="w">    </span><span class="k">end do</span>
<a id="ln-312" name="ln-312" href="#ln-312"></a>
<a id="ln-313" name="ln-313" href="#ln-313"></a><span class="k">  end procedure</span>
<a id="ln-314" name="ln-314" href="#ln-314"></a>
<a id="ln-315" name="ln-315" href="#ln-315"></a><span class="k">  module procedure </span><span class="n">double_precision_neurons_per_layer</span>
<a id="ln-316" name="ln-316" href="#ln-316"></a>
<a id="ln-317" name="ln-317" href="#ln-317"></a><span class="w">    </span><span class="k">type</span><span class="p">(</span><span class="n">neuron_t</span><span class="p">(</span><span class="n">double_precision</span><span class="p">)),</span><span class="w"> </span><span class="k">pointer</span><span class="w"> </span><span class="kd">::</span><span class="w">  </span><span class="n">neuron</span><span class="w"> </span>
<a id="ln-318" name="ln-318" href="#ln-318"></a>
<a id="ln-319" name="ln-319" href="#ln-319"></a><span class="w">    </span><span class="n">neuron</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">self</span><span class="p">%</span><span class="n">neuron</span>
<a id="ln-320" name="ln-320" href="#ln-320"></a><span class="w">    </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-321" name="ln-321" href="#ln-321"></a><span class="w">    </span><span class="k">do </span>
<a id="ln-322" name="ln-322" href="#ln-322"></a><span class="k">      if</span><span class="w"> </span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="w"> </span><span class="n">neuron</span><span class="p">%</span><span class="n">next_allocated</span><span class="p">())</span><span class="w"> </span><span class="k">exit</span>
<a id="ln-323" name="ln-323" href="#ln-323"></a><span class="k">      </span><span class="n">neuron</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">neuron</span><span class="p">%</span><span class="n">next_pointer</span><span class="p">()</span>
<a id="ln-324" name="ln-324" href="#ln-324"></a><span class="w">      </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_neurons</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<a id="ln-325" name="ln-325" href="#ln-325"></a><span class="w">    </span><span class="k">end do</span>
<a id="ln-326" name="ln-326" href="#ln-326"></a>
<a id="ln-327" name="ln-327" href="#ln-327"></a><span class="k">  end procedure</span>
<a id="ln-328" name="ln-328" href="#ln-328"></a>
<a id="ln-329" name="ln-329" href="#ln-329"></a><span class="k">  module procedure </span><span class="n">default_real_next_allocated</span>
<a id="ln-330" name="ln-330" href="#ln-330"></a><span class="w">    </span><span class="n">next_is_allocated</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">allocated</span><span class="p">(</span><span class="n">self</span><span class="p">%</span><span class="n">next</span><span class="p">)</span>
<a id="ln-331" name="ln-331" href="#ln-331"></a><span class="w">  </span><span class="k">end procedure</span>
<a id="ln-332" name="ln-332" href="#ln-332"></a>
<a id="ln-333" name="ln-333" href="#ln-333"></a><span class="k">  module procedure </span><span class="n">double_precision_next_allocated</span>
<a id="ln-334" name="ln-334" href="#ln-334"></a><span class="w">    </span><span class="n">next_is_allocated</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">allocated</span><span class="p">(</span><span class="n">self</span><span class="p">%</span><span class="n">next</span><span class="p">)</span>
<a id="ln-335" name="ln-335" href="#ln-335"></a><span class="w">  </span><span class="k">end procedure</span>
<a id="ln-336" name="ln-336" href="#ln-336"></a>
<a id="ln-337" name="ln-337" href="#ln-337"></a><span class="k">  module procedure </span><span class="n">default_real_next_pointer</span>
<a id="ln-338" name="ln-338" href="#ln-338"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">allocated</span><span class="p">(</span><span class="n">self</span><span class="p">%</span><span class="n">next</span><span class="p">))</span><span class="w"> </span><span class="k">then</span>
<a id="ln-339" name="ln-339" href="#ln-339"></a><span class="k">      </span><span class="n">next_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">self</span><span class="p">%</span><span class="n">next</span>
<a id="ln-340" name="ln-340" href="#ln-340"></a><span class="w">    </span><span class="k">else</span>
<a id="ln-341" name="ln-341" href="#ln-341"></a><span class="k">      </span><span class="n">next_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="nb">null</span><span class="p">()</span>
<a id="ln-342" name="ln-342" href="#ln-342"></a><span class="w">    </span><span class="k">end if</span>
<a id="ln-343" name="ln-343" href="#ln-343"></a><span class="k">  end procedure</span>
<a id="ln-344" name="ln-344" href="#ln-344"></a>
<a id="ln-345" name="ln-345" href="#ln-345"></a><span class="k">  module procedure </span><span class="n">double_precision_next_pointer</span>
<a id="ln-346" name="ln-346" href="#ln-346"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">allocated</span><span class="p">(</span><span class="n">self</span><span class="p">%</span><span class="n">next</span><span class="p">))</span><span class="w"> </span><span class="k">then</span>
<a id="ln-347" name="ln-347" href="#ln-347"></a><span class="k">      </span><span class="n">next_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">self</span><span class="p">%</span><span class="n">next</span>
<a id="ln-348" name="ln-348" href="#ln-348"></a><span class="w">    </span><span class="k">else</span>
<a id="ln-349" name="ln-349" href="#ln-349"></a><span class="k">      </span><span class="n">next_ptr</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="nb">null</span><span class="p">()</span>
<a id="ln-350" name="ln-350" href="#ln-350"></a><span class="w">    </span><span class="k">end if</span>
<a id="ln-351" name="ln-351" href="#ln-351"></a><span class="k">  end procedure</span>
<a id="ln-352" name="ln-352" href="#ln-352"></a>
<a id="ln-353" name="ln-353" href="#ln-353"></a><span class="k">end submodule </span><span class="n">layer_s</span>
</pre></div>

      </section>
    </div>
  </div>

      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col">
            <p>
              Fiats
 was developed by Berkeley Lab<br>              &copy; 2024 
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
 on 2024-10-17 00:07              </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>    

    <!-- MathJax JavaScript
             ================================================== -->
             <!-- Placed at the end of the document so the pages load faster -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
          jax: ['input/TeX','input/MathML','output/HTML-CSS'],
          extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
          });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

          <script src="../tipuesearch/tipuesearch_content.js"></script>
          <script src="../tipuesearch/tipuesearch_set.js"></script>
          <script src="../tipuesearch/tipuesearch.js"></script>

  </body>
</html>